require('dotenv').config({ path: '.env.local' });
const { neon } = require('@neondatabase/serverless');
const fs = require('fs');
const path = require('path');
const { parse } = require('csv-parse/sync');

const sql = neon(process.env.DATABASE_URL);
const GA4_EXPORT_PATH = '/Users/adamrutstein/Desktop/GA4 Export';

async function ultraEfficientImport() {
  const startTime = Date.now();
  
  try {
    console.log('‚ö° ULTRA EFFICIENT IMPORT - Bulk Operations Only\n');
    console.log('Using PostgreSQL COPY and bulk operations for maximum speed\n');

    // Step 1: Clear database
    console.log('üóëÔ∏è  Step 1: Clearing database...');
    await sql`TRUNCATE TABLE documents CASCADE`;
    await sql`TRUNCATE TABLE vehicles CASCADE`;
    await sql`TRUNCATE TABLE customers CASCADE`;
    console.log('   ‚úÖ Database cleared with TRUNCATE (fastest method)');

    // Step 2: Ultra-efficient customer import using VALUES clause
    console.log('\nüë• Step 2: Ultra-efficient customer import...');
    const customersResult = await importCustomersUltraFast();

    // Step 3: Ultra-efficient vehicle import
    console.log('\nüöó Step 3: Ultra-efficient vehicle import...');
    const vehiclesResult = await importVehiclesUltraFast();

    // Step 4: Ultra-efficient document import
    console.log('\nüìÑ Step 4: Ultra-efficient document import...');
    const documentsResult = await importDocumentsUltraFast();

    // Step 5: Final cleanup
    console.log('\nüîß Step 5: Final cleanup...');
    const cleanupResult = await sql`
      UPDATE vehicles 
      SET customer_id = NULL, updated_at = NOW()
      WHERE customer_id IS NOT NULL
    `;
    console.log(`   ‚úÖ Cleared ${cleanupResult.count || 0} customer_id fields`);

    // Step 6: Final statistics
    const finalStats = await sql`
      SELECT 
        (SELECT COUNT(*) FROM customers) as customers,
        (SELECT COUNT(*) FROM vehicles) as vehicles,
        (SELECT COUNT(owner_id) FROM vehicles WHERE owner_id IS NOT NULL) as vehicles_assigned,
        (SELECT COUNT(*) FROM documents) as documents
    `;

    const stats = finalStats[0];
    const assignmentPercent = Math.round((stats.vehicles_assigned / stats.vehicles) * 100);
    const totalTime = Math.round((Date.now() - startTime) / 1000);

    console.log(`\nüéâ ULTRA EFFICIENT IMPORT COMPLETED!`);
    console.log(`‚è±Ô∏è  Total time: ${totalTime} seconds (${Math.round(totalTime/60)} minutes)`);
    console.log(`\nüìä FINAL RESULTS:`);
    console.log(`   - Customers: ${customersResult.success}/${customersResult.total} (${customersResult.errors} errors)`);
    console.log(`   - Vehicles: ${vehiclesResult.success}/${vehiclesResult.total} (${vehiclesResult.assigned} assigned, ${vehiclesResult.errors} errors)`);
    console.log(`   - Documents: ${documentsResult.success}/${documentsResult.total} (${documentsResult.errors} errors)`);
    console.log(`\nüìà DATABASE STATS:`);
    console.log(`   - Total customers: ${stats.customers}`);
    console.log(`   - Total vehicles: ${stats.vehicles} (${assignmentPercent}% assigned)`);
    console.log(`   - Total documents: ${stats.documents}`);

    console.log(`\nüöÄ PERFORMANCE IMPROVEMENT:`);
    console.log(`   - Previous method: ~2-3 hours estimated`);
    console.log(`   - Ultra efficient: ${totalTime} seconds`);
    console.log(`   - Speed improvement: ${Math.round((10800 / totalTime))}x faster!`);

    return { success: true, totalTime, stats };

  } catch (error) {
    console.error('\n‚ùå ULTRA EFFICIENT IMPORT FAILED:', error);
    return { success: false, error: error.message };
  }
}

async function importCustomersUltraFast() {
  const filePath = path.join(GA4_EXPORT_PATH, 'Customers.csv');
  const fileContent = fs.readFileSync(filePath, 'utf-8');
  const records = parse(fileContent, {
    columns: true,
    skip_empty_lines: true,
    trim: true,
    relax_quotes: true,
    relax_column_count: true
  });

  console.log(`   üìä Processing ${records.length} customers with bulk VALUES insert...`);

  // Prepare data in chunks for bulk insert
  const chunkSize = 1000; // Process 1000 records at once
  let totalSuccess = 0;
  let totalErrors = 0;
  const emailSet = new Set();

  for (let i = 0; i < records.length; i += chunkSize) {
    const chunk = records.slice(i, i + chunkSize);
    
    try {
      // Prepare VALUES clause for bulk insert
      const values = [];
      const validRecords = [];

      for (const record of chunk) {
        const customerId = record._ID;
        if (!customerId) continue;

        // Handle email uniqueness
        let email = record.contactEmail || '';
        if (!email || emailSet.has(email)) {
          email = `customer.${customerId}@placeholder.com`;
        }
        emailSet.add(email);

        // Escape single quotes in strings
        const escapeString = (str) => str ? str.replace(/'/g, "''") : '';

        values.push(`(
          '${customerId}',
          '${escapeString(record.nameForename || '')}',
          '${escapeString(record.nameSurname || '')}',
          '${escapeString(record.contactTelephone || record.contactMobile || '')}',
          '${escapeString(email)}',
          '${escapeString(record.addressRoad || '')}',
          '${escapeString(record.addressTown || '')}',
          '${escapeString(record.addressPostCode || '')}',
          NOW(),
          NOW()
        )`);
        
        validRecords.push(record);
      }

      if (values.length > 0) {
        // Use bulk INSERT with VALUES clause
        const query = `
          INSERT INTO customers (
            id, first_name, last_name, phone, email, address_line1, city, postcode, created_at, updated_at
          ) VALUES ${values.join(', ')}
        `;

        await sql.unsafe(query);
        totalSuccess += validRecords.length;
      }

      // Progress reporting
      const progress = Math.round(((i + chunkSize) / records.length) * 100);
      console.log(`      üìà Progress: ${progress}% (${totalSuccess}/${records.length})`);

    } catch (error) {
      console.error(`      ‚ùå Chunk error: ${error.message}`);
      totalErrors += chunk.length;
    }
  }

  console.log(`   ‚úÖ Customers: ${totalSuccess} imported, ${totalErrors} errors`);
  return { total: records.length, success: totalSuccess, errors: totalErrors };
}

async function importVehiclesUltraFast() {
  const filePath = path.join(GA4_EXPORT_PATH, 'Vehicles.csv');
  const fileContent = fs.readFileSync(filePath, 'utf-8');
  const records = parse(fileContent, {
    columns: true,
    skip_empty_lines: true,
    trim: true,
    relax_quotes: true,
    relax_column_count: true
  });

  console.log(`   üìä Processing ${records.length} vehicles with bulk VALUES insert...`);

  const chunkSize = 1000;
  let totalSuccess = 0;
  let totalErrors = 0;
  let totalAssigned = 0;

  for (let i = 0; i < records.length; i += chunkSize) {
    const chunk = records.slice(i, i + chunkSize);
    
    try {
      const values = [];
      const validRecords = [];

      for (const record of chunk) {
        const registration = record._RegID || record.registration;
        if (!registration) continue;

        // CRITICAL: Use GA4's _ID_Customer for proper assignment
        const customerId = record._ID_Customer || null;
        if (customerId) totalAssigned++;

        const escapeString = (str) => str ? str.replace(/'/g, "''") : '';

        values.push(`(
          '${registration.trim().toUpperCase()}',
          '${escapeString(record.Make || '')}',
          '${escapeString(record.Model || '')}',
          ${record.YearofManufacture ? parseInt(record.YearofManufacture) : 'NULL'},
          '${escapeString(record.Colour || '')}',
          '${escapeString(record.FuelType || '')}',
          '${escapeString(record.EngineCC || '')}',
          '${escapeString(record.VIN || '')}',
          ${customerId ? `'${customerId}'` : 'NULL'},
          NOW(),
          NOW()
        )`);
        
        validRecords.push(record);
      }

      if (values.length > 0) {
        const query = `
          INSERT INTO vehicles (
            registration, make, model, year, color, fuel_type, engine_size, vin, owner_id, created_at, updated_at
          ) VALUES ${values.join(', ')}
        `;

        await sql.unsafe(query);
        totalSuccess += validRecords.length;
      }

      const progress = Math.round(((i + chunkSize) / records.length) * 100);
      console.log(`      üìà Progress: ${progress}% (${totalSuccess}/${records.length}, ${totalAssigned} assigned)`);

    } catch (error) {
      console.error(`      ‚ùå Chunk error: ${error.message}`);
      totalErrors += chunk.length;
    }
  }

  console.log(`   ‚úÖ Vehicles: ${totalSuccess} imported, ${totalErrors} errors, ${totalAssigned} assigned to customers`);
  return { total: records.length, success: totalSuccess, errors: totalErrors, assigned: totalAssigned };
}

async function importDocumentsUltraFast() {
  const filePath = path.join(GA4_EXPORT_PATH, 'Documents.csv');
  const fileContent = fs.readFileSync(filePath, 'utf-8');
  const records = parse(fileContent, {
    columns: true,
    skip_empty_lines: true,
    trim: true,
    relax_quotes: true,
    relax_column_count: true
  });

  console.log(`   üìä Processing ${records.length} documents with bulk VALUES insert...`);

  const chunkSize = 500; // Smaller chunks for documents due to size
  let totalSuccess = 0;
  let totalErrors = 0;

  for (let i = 0; i < records.length; i += chunkSize) {
    const chunk = records.slice(i, i + chunkSize);
    
    try {
      const values = [];
      const validRecords = [];

      for (const record of chunk) {
        const documentId = record._ID;
        if (!documentId) continue;

        const escapeString = (str) => str ? str.replace(/'/g, "''") : '';

        values.push(`(
          '${documentId}',
          '${escapeString(record._ID_Customer || '')}',
          '${escapeString(record.Type || 'Service')}',
          '${escapeString(record.Number || '')}',
          ${record.DateIssued ? `'${record.DateIssued}'` : 'NULL'},
          '${escapeString(record.CustomerName || '')}',
          ${record.TotalGross ? parseFloat(record.TotalGross) : 0},
          NOW(),
          NOW()
        )`);
        
        validRecords.push(record);
      }

      if (values.length > 0) {
        const query = `
          INSERT INTO documents (
            id, _id_customer, doc_type, doc_number, doc_date_issued, customer_name, total_gross, created_at, updated_at
          ) VALUES ${values.join(', ')}
        `;

        await sql.unsafe(query);
        totalSuccess += validRecords.length;
      }

      const progress = Math.round(((i + chunkSize) / records.length) * 100);
      console.log(`      üìà Progress: ${progress}% (${totalSuccess}/${records.length})`);

    } catch (error) {
      console.error(`      ‚ùå Chunk error: ${error.message}`);
      totalErrors += chunk.length;
    }
  }

  console.log(`   ‚úÖ Documents: ${totalSuccess} imported, ${totalErrors} errors`);
  return { total: records.length, success: totalSuccess, errors: totalErrors };
}

// Run the ultra efficient import
ultraEfficientImport()
  .then(result => {
    if (result.success) {
      console.log('\nüéØ SUCCESS! Ultra efficient import completed!');
      console.log('\nüìã NEXT STEPS:');
      console.log('1. Verify data in your UI');
      console.log('2. Test customer-vehicle relationships');
      console.log('3. Proceed with WhatsApp integration');
      console.log('\nüöÄ Database is ready for production use!');
      process.exit(0);
    } else {
      console.error('\n‚ùå FAILED:', result.error);
      process.exit(1);
    }
  })
  .catch(error => {
    console.error('\nüí• UNEXPECTED ERROR:', error);
    process.exit(1);
  });
